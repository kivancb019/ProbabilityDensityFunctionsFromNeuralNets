{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9785ff14",
   "metadata": {},
   "source": [
    "## Shaft model for PDF shaping (656 samples)\n",
    "\n",
    "* This uses the new object oriented class for PDF shaping\n",
    "\n",
    "* This model uses the CFD Shaft data with 656 samples\n",
    "\n",
    "## Web application 6 inputs and 5 outputs\n",
    "\n",
    "Run interactively on the web at:\n",
    "\n",
    "## Inputs\n",
    "\n",
    "(1, 'i_pul_coal_inj_kg_thm')\n",
    "\n",
    "(2, 'i_nat_gas_inj_kg_thm')\n",
    "\n",
    "(3, 'i_nat_gas_t_k')\n",
    "\n",
    "(4, 'i_o2_vol_perce')\n",
    "\n",
    "(9, 'i_ore_moisture_weight_perce')\n",
    "\n",
    "(11, 'i_ore_weight_kg')\n",
    "\n",
    "## Outputs\n",
    "\n",
    "(19, 'o_shaft_co_utiliz')\n",
    "\n",
    "(20, 'o_shaft_h2_utiliz')\n",
    "\n",
    "(21, 'o_shaft_top_gas_temp_c')\n",
    "\n",
    "(22, 'o_shaft_press_drop_pa')\n",
    "\n",
    "(23, 'o_shaft_coke_rate_kg_thm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import random\n",
    "import functorch\n",
    "\n",
    "from numpy.random import normal\n",
    "from scipy.stats import norm\n",
    "import scipy.stats as stats\n",
    "from numpy import hstack\n",
    "from numpy import vstack\n",
    "from numpy import exp\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "##from typing import Optional\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from mlxtend.plotting import heatmap\n",
    "\n",
    "## coefficient of determination (R**2)\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "torch.set_printoptions(sci_mode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af350428",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import PDFshapingUtils as PDF_tk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba3fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFshapingOBJ = PDF_tk.PDFshapingUtils()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9b5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFshapingOBJ.initializeImpulseGaussian()\n",
    "\n",
    "print(PDFshapingOBJ.x_range_impulse_func )\n",
    "print(PDFshapingOBJ.impulse_func_vector_vals )\n",
    "print(PDFshapingOBJ.x_range_impulse_func.shape )\n",
    "print(PDFshapingOBJ.impulse_func_vector_vals.shape )\n",
    " \n",
    "print( sum(PDFshapingOBJ.impulse_func_vector_vals) )      ## should add up to 100 (i.e. 1.0 prob density)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7837eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(PDFshapingOBJ.x_range_impulse_func, PDFshapingOBJ.impulse_func_vector_vals)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8475848",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFshapingOBJ.test_torchKDE_with_fake_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b59b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFshapingOBJ.read_csv_file_with_pandas('CFD.10.2022.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbed683",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFshapingOBJ.CFD_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67de286",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFshapingOBJ.print_headers_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcffa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFshapingOBJ.list_of_selected_column_names = ['i_pul_coal_inj_kg_thm','i_nat_gas_inj_kg_thm',\n",
    "            'i_nat_gas_t_k','i_o2_vol_perce', 'i_ore_moisture_weight_perce', 'i_ore_weight_kg', \n",
    "            'o_shaft_co_utiliz', 'o_shaft_h2_utiliz', 'o_shaft_top_gas_temp_c', 'o_shaft_press_drop_pa', \n",
    "            'o_shaft_coke_rate_kg_thm']\n",
    "\n",
    "PDFshapingOBJ.print_correlation_coefficients()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c308c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFshapingOBJ.convert_pd_data_to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c02d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFshapingOBJ.gen_X_y_for_selected_indeces(  \n",
    "                   inputs=[1, 2, 3, 4, 9, 11] , \n",
    "                   outputs=[19, 20, 21, 22, 23]   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c76c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(PDFshapingOBJ.X.shape)\n",
    "print(PDFshapingOBJ.y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1ab012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFshapingOBJ.random_seed = int( random.random() * 100  )         ## defautl is 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89408382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFshapingOBJ.split_np_data_train_test(selected_test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f60b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFshapingOBJ.convert_dataset_from_np_to_torch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f209b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFshapingOBJ.standardize_X_scales()\n",
    "PDFshapingOBJ.standardize_y_scales()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb941c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFshapingOBJ.gen_Dataloader_train()\n",
    "\n",
    "PDFshapingOBJ.train_dl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb6939f",
   "metadata": {},
   "source": [
    "## NN architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################################################\n",
    "## Linear Regression\n",
    "\n",
    "class LinRegNet_SIO(nn.Module):\n",
    "    ## initialize the layers\n",
    "    def __init__(self, x_means, x_deviations, y_means, y_deviations):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.x_means      = x_means\n",
    "        self.x_deviations = x_deviations\n",
    "        self.y_means      = y_means\n",
    "        self.y_deviations = y_deviations\n",
    "        \n",
    "        self.linear1 = nn.Linear(6, 5) \n",
    "        \n",
    "        ## nn.init.xavier_uniform_(self.linear1.weight)\n",
    "        ## nn.init.zeros_(self.linear1.bias)\n",
    "\n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        x = (x - self.x_means) / self.x_deviations\n",
    "        \n",
    "        y_scaled = self.linear1(x)\n",
    "        y_descaled = y_scaled * self.y_deviations + self.y_means\n",
    "        \n",
    "        return y_descaled, y_scaled\n",
    "\n",
    "    \n",
    "#############################################################\n",
    "## Multi-Layer Perceptron\n",
    "\n",
    "class MLP_Net_SIO(nn.Module):\n",
    "    ## initialize the layers\n",
    "    def __init__(self, x_means, x_deviations, y_means, y_deviations):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.x_means      = x_means\n",
    "        self.x_deviations = x_deviations\n",
    "        self.y_means      = y_means\n",
    "        self.y_deviations = y_deviations\n",
    "        \n",
    "        self.linear1 = nn.Linear(6, 10)\n",
    "        self.act1    = nn.Sigmoid()                       ## Tanh() \n",
    "        self.linear2 = nn.Linear(10, 5)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        ## nn.init.xavier_uniform_(self.linear1.weight)\n",
    "        ## nn.init.zeros_(self.linear1.bias)\n",
    "        \n",
    "        ## nn.init.xavier_uniform_(self.linear2.weight)\n",
    "        ## nn.init.zeros_(self.linear2.bias)\n",
    "    \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        x = (x - self.x_means) / self.x_deviations\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        y_scaled = self.linear2(x)\n",
    "        y_descaled = y_scaled * self.y_deviations + self.y_means\n",
    "        \n",
    "        return y_descaled, y_scaled\n",
    "    \n",
    "\n",
    "#############################################################\n",
    "## Deep Learning model with 2 hidden layers\n",
    "\n",
    "\n",
    "class DL_Net_SIO(nn.Module):\n",
    "    \n",
    "    ## initialize the layers\n",
    "    def __init__(self, x_means, x_deviations, y_means, y_deviations):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.x_means      = x_means\n",
    "        self.x_deviations = x_deviations\n",
    "        self.y_means      = y_means\n",
    "        self.y_deviations = y_deviations\n",
    "        \n",
    "        self.linear1 = nn.Linear(6, 10)\n",
    "        self.act1    = nn.Sigmoid()                       ## Tanh() \n",
    "        self.linear2 = nn.Linear(10, 6)\n",
    "        self.act2    = nn.Sigmoid() \n",
    "        self.linear3 = nn.Linear(6, 5)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        ## nn.init.xavier_uniform_(self.linear1.weight)\n",
    "        ## nn.init.zeros_(self.linear1.bias)\n",
    "        \n",
    "        ## nn.init.xavier_uniform_(self.linear2.weight)\n",
    "        ## nn.init.zeros_(self.linear2.bias)\n",
    "        \n",
    "        ## nn.init.xavier_uniform_(self.linear3.weight)\n",
    "        ## nn.init.zeros_(self.linear3.bias)\n",
    "    \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = (x - self.x_means) / self.x_deviations\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        y_scaled = self.linear3(x)\n",
    "        y_descaled = y_scaled * self.y_deviations + self.y_means\n",
    "        \n",
    "        return y_descaled, y_scaled\n",
    "\n",
    "      \n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87589b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#############################################################\n",
    "##   F1      plus       F2\n",
    "## Linear     +      Nonlinear\n",
    "\n",
    "class F1plusF2_SIO(nn.Module):\n",
    "    ## initialize the layers\n",
    "    def __init__(self, x_means, x_deviations, y_means, y_deviations):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.x_means      = x_means\n",
    "        self.x_deviations = x_deviations\n",
    "        self.y_means      = y_means\n",
    "        self.y_deviations = y_deviations\n",
    "        \n",
    "        ## F1\n",
    "        self.f1_linear1 = nn.Linear(6, 5)       \n",
    "        \n",
    "        ## F2\n",
    "        self.f2_linear1 = nn.Linear(6, 10)\n",
    "        self.f2_act1    = nn.Sigmoid()                    ## Tanh()                       \n",
    "        self.f2_linear2 = nn.Linear(10, 5)       \n",
    "        self.f2_dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        x = (x - self.x_means) / self.x_deviations\n",
    "        \n",
    "        ## F1\n",
    "        f1 = self.f1_linear1(x)\n",
    "        \n",
    "        ## F2\n",
    "        f2 = self.f2_linear1(x)\n",
    "        f2 = self.f2_act1(f2)\n",
    "        f2 = self.f2_dropout(f2)\n",
    "        f2 = self.f2_linear2(f2)\n",
    "        \n",
    "        \n",
    "        y_scaled   = f1 + f2\n",
    "        y_descaled = y_scaled * self.y_deviations + self.y_means\n",
    "        \n",
    "        return y_descaled, y_scaled\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dd05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_loss_UNKNOWN_error_PDF(epoch, output, target):\n",
    "    error = output.float() - target.float()                            ## 400 X 5\n",
    "    impulseFunc = ImpulseGaussian(x, mean_impulse, std_impulse**2)        ## 4000 X 1\n",
    "    basisFunc = train_multiple_kernels_per_output(x, error, bandwidth)    ## 4000 x 5\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print_errors_kdes(error, x, basisFunc)\n",
    "        print(impulseFunc.shape)\n",
    "        print(basisFunc.shape)\n",
    "    \n",
    "    basisFunc = basisFunc.T\n",
    "    diff = ( basisFunc.float() -  impulseFunc.float()  )                 ## 4000 x 5\n",
    "    loss = torch.mean(   (   diff  )**2    )   \n",
    "    ## reg_sigma_func = (loss ** 2) * use_regularization\n",
    "    ## loss = loss * ( 1.0 + reg_sigma_func )\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8a32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_loss_known_is_gauss(output, target):\n",
    "       \n",
    "    error = output.float() - target.float() \n",
    "    basisFunc   =  kernel_density(x, error, h)\n",
    "    diff = ( basisFunc.float() -  impulseFunc.float()  )        \n",
    "    loss = torch.mean(   (   diff  )**2    )    ## / h\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de738f24",
   "metadata": {},
   "source": [
    "## Results for g(x) = F1(x) + F2(x) with No PDF shaping\n",
    "\n",
    "F1 = Linear\n",
    "\n",
    "F2 = Nonlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5922af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_y_scaled(num_epochs, model, loss_fn, opt):\n",
    "    \n",
    "    PDFshapingOBJ.list_metric = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for xb, yb in PDFshapingOBJ.train_dl:\n",
    "            pred_descaled, pred_scaled = model(xb)\n",
    "            loss = loss_fn(pred_scaled, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        if epoch % 200 == 0:\n",
    "            print(epoch, \" loss= \", loss)\n",
    "            \n",
    "            \n",
    "        pred_descaled, pred_scaled = model(PDFshapingOBJ.X_train_tr)\n",
    "        r2_avg = torch.mean(\n",
    "            torch.tensor(\n",
    "                r2_score( pred_scaled.detach().numpy(),  PDFshapingOBJ.y_train_tr_scaled.numpy()   )\n",
    "            )\n",
    "        )\n",
    "        PDFshapingOBJ.list_metric.append(  r2_avg.detach().numpy()  )\n",
    "            \n",
    "    PDFshapingOBJ.func_plot_performance()\n",
    "            \n",
    "    pred_descaled, pred_scaled = model(PDFshapingOBJ.X_train_tr)\n",
    "    print('Training loss:', loss_fn(  pred_scaled,           PDFshapingOBJ.y_train_tr_scaled          ))\n",
    "    print('Training R**2:', r2_score( pred_scaled.detach().numpy(), PDFshapingOBJ.y_train_tr_scaled.numpy()  ))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10288bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFshapingOBJ.the_string           = \"No_PDF_shaping\"\n",
    "PDFshapingOBJ.furnace_model_name   = \"shaft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75353e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = F1plusF2_SIO(\n",
    "             PDFshapingOBJ.x_means, \n",
    "             PDFshapingOBJ.x_deviations, \n",
    "             PDFshapingOBJ.y_means, \n",
    "             PDFshapingOBJ.y_deviations\n",
    ")\n",
    "\n",
    "opt = torch.optim.Adam(   model.parameters(), lr=PDFshapingOBJ.learning_rate   )\n",
    "loss_fn = F.mse_loss\n",
    "\n",
    "\n",
    "fit_y_scaled(PDFshapingOBJ.N_EPOCHS, model, loss_fn, opt)\n",
    "\n",
    "\n",
    "pred_descaled, pred_scaled = model(PDFshapingOBJ.X_test_tr)\n",
    "print('Test loss - scaled:',   loss_fn(     pred_scaled,         PDFshapingOBJ.y_test_tr_scaled          ))\n",
    "print('Test loss - descaled:', loss_fn(     pred_descaled,       PDFshapingOBJ.y_test_tr                 ))\n",
    "print('Testing R**2 - scaled:', r2_score( pred_scaled.detach().numpy(), PDFshapingOBJ.y_test_tr_scaled.numpy() ))\n",
    "print('Testing R**2 - descaled:', r2_score( pred_descaled.detach().numpy(), PDFshapingOBJ.y_test_tr.numpy()    ))\n",
    "\n",
    "PDFshapingOBJ.print_individual_Rsquare(pred_descaled, PDFshapingOBJ.y_test_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73152e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_preds = []\n",
    "list_reals = []\n",
    "\n",
    "for i in range(len(PDFshapingOBJ.X_test_tr)):\n",
    "    print(\"**************************************************\")\n",
    "    print(\"preds, real\")\n",
    "    preds_descaled, preds_scaled = model(PDFshapingOBJ.X_test_tr[i])\n",
    "\n",
    "    np_pred = preds_descaled[0].detach().numpy()              ## [0]\n",
    "    np_real = PDFshapingOBJ.y_test_tr[i].detach().numpy()\n",
    "\n",
    "    for j in range(len(np_pred)):\n",
    "        print((np_pred[j], np_real[j]))\n",
    "        list_preds.append(np_pred[j])\n",
    "        list_reals.append(np_real[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e16398",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFshapingOBJ.plot_preds_vs_reals( list_preds, list_reals )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e6996",
   "metadata": {},
   "source": [
    "## Results for g(x) = F1(x) + F2(x) with PDF shaping\n",
    "\n",
    "F1 = Linear\n",
    "\n",
    "F2 = Nonlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c149c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_y_scaled_PDF(num_epochs, num_epochs_pdf, model, loss_fn, loss_fn_PDF, opt):\n",
    "    \n",
    "    PDFshapingOBJ.list_metric = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for xb, yb in PDFshapingOBJ.train_dl:\n",
    "            \n",
    "            pred_descaled, pred_scaled = model(xb)\n",
    "            loss = loss_fn(pred_scaled, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        if epoch % 200 == 0:\n",
    "            print(epoch, \" loss= \", loss)\n",
    "        \n",
    "        pred_descaled, pred_scaled = model(PDFshapingOBJ.X_train_tr)\n",
    "        r2_avg = torch.mean(torch.tensor(\n",
    "                r2_score( pred_scaled.detach().numpy(),  PDFshapingOBJ.y_train_tr_scaled.numpy()  )\n",
    "        ))\n",
    "        PDFshapingOBJ.list_metric.append(r2_avg.detach().numpy())\n",
    "        \n",
    "        \n",
    "    ## opt = torch.optim.Adam(   model.parameters(), lr=learning_rate_pdfcontrol   )    \n",
    "        \n",
    "    for epoch in range(num_epochs_pdf):\n",
    "        \n",
    "        pred_descaled, pred_scaled = model(PDFshapingOBJ.X_train_tr)\n",
    "        \n",
    "        ## loss = loss_fn_PDF(  epoch, pred_scaled,    PDFshapingOBJ.y_train_tr_scaled  )\n",
    "        \n",
    "        error = pred_scaled.float() - PDFshapingOBJ.y_train_tr_scaled.float()        ## 524  X 5\n",
    "        basisFunc = PDFshapingOBJ.train_multiple_kernels_per_output( error )         ## 4000 x 5\n",
    "        \n",
    "        ## print(\"pred_scaled\", pred_scaled.shape)\n",
    "        ## print(\"y_train_tr_scaled\", PDFshapingOBJ.y_train_tr_scaled.shape)\n",
    "        ## print(\"error\", error.shape)\n",
    "        ## print(\"basisFunc \", basisFunc.shape )\n",
    "        ## print(\"impulse_func_vector_vals\", PDFshapingOBJ.impulse_func_vector_vals.shape)\n",
    "        ## print(PDFshapingOBJ.impulse_func_vector_vals.unsqueeze(1).shape)\n",
    "      \n",
    "        \n",
    "        diff = ( basisFunc.float() - PDFshapingOBJ.impulse_func_vector_vals.unsqueeze(1).float() )   ## 4000 x 5\n",
    "        loss = torch.mean(   (   diff  )**2    )  \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "  \n",
    "        print(epoch, \" loss= \", loss)\n",
    "        if epoch % 50 == 0:\n",
    "            print(error.shape)\n",
    "            print(basisFunc.shape)\n",
    "            PDFshapingOBJ.print_errors_kdes(  error, basisFunc )\n",
    "            print(PDFshapingOBJ.impulse_func_vector_vals.shape)\n",
    "      \n",
    "\n",
    "        r2_avg = torch.mean(torch.tensor(\n",
    "                 r2_score( pred_scaled.detach().numpy(),  PDFshapingOBJ.y_train_tr_scaled.numpy()  )\n",
    "        ))\n",
    "        PDFshapingOBJ.list_metric.append(  r2_avg.detach().numpy()  )\n",
    "        \n",
    "        \n",
    "            \n",
    "    PDFshapingOBJ.func_plot_performance()\n",
    "            \n",
    "    pred_descaled, pred_scaled = model(PDFshapingOBJ.X_train_tr)\n",
    "    print('Training loss:', loss_fn(  pred_scaled,       PDFshapingOBJ.y_train_tr_scaled          ))\n",
    "    print('Training R**2:', r2_score( pred_scaled.detach().numpy(), PDFshapingOBJ.y_train_tr_scaled.numpy() ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9bb8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFshapingOBJ.the_string           = \"With_PDF_shaping\"\n",
    "PDFshapingOBJ.furnace_model_name   = \"shaft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d69f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = F1plusF2_SIO(\n",
    "          PDFshapingOBJ.x_means, \n",
    "          PDFshapingOBJ.x_deviations, \n",
    "          PDFshapingOBJ.y_means, \n",
    "          PDFshapingOBJ.y_deviations\n",
    ")\n",
    "\n",
    "opt = torch.optim.Adam(   model.parameters(), lr=PDFshapingOBJ.learning_rate   )\n",
    "loss_fn     = F.mse_loss\n",
    "loss_fn_PDF = my_loss_UNKNOWN_error_PDF\n",
    "\n",
    "fit_y_scaled_PDF(PDFshapingOBJ.N_EPOCHS, PDFshapingOBJ.N_EPOCHS_PDF, model, loss_fn, loss_fn_PDF, opt)\n",
    "\n",
    "pred_descaled, pred_scaled = model(PDFshapingOBJ.X_test_tr)\n",
    "print('Test loss - scaled:',   loss_fn(     pred_scaled,       PDFshapingOBJ.y_test_tr_scaled          ))\n",
    "print('Test loss - descaled:', loss_fn(     pred_descaled,     PDFshapingOBJ.y_test_tr                 ))\n",
    "print('Testing R**2 - scaled:',   r2_score( pred_scaled.detach().numpy(),PDFshapingOBJ.y_test_tr_scaled.numpy() ))\n",
    "print('Testing R**2 - descaled:', r2_score( pred_descaled.detach().numpy(), PDFshapingOBJ.y_test_tr.numpy()   ))\n",
    "\n",
    "\n",
    "PDFshapingOBJ.print_individual_Rsquare(pred_descaled, PDFshapingOBJ.y_test_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d7566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_preds = []\n",
    "list_reals = []\n",
    "\n",
    "for i in range(len(PDFshapingOBJ.X_test_tr)):\n",
    "    print(\"**************************************************\")\n",
    "    print(\"preds, real\")\n",
    "    preds_descaled, preds_scaled = model(PDFshapingOBJ.X_test_tr[i])\n",
    "\n",
    "    np_pred = preds_descaled[0].detach().numpy()              ## [0]\n",
    "    np_real = PDFshapingOBJ.y_test_tr[i].detach().numpy()\n",
    "\n",
    "    for j in range(len(np_pred)):\n",
    "        print((np_pred[j], np_real[j]))\n",
    "        list_preds.append(np_pred[j])\n",
    "        list_reals.append(np_real[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa3845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFshapingOBJ.plot_preds_vs_reals( list_preds, list_reals )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd737b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
